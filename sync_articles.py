import os
import aiohttp
import asyncio
import feedparser
from datetime import datetime
from bs4 import BeautifulSoup
import logging

# é…ç½®
TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
TELEGRAM_CHANNEL_ID = os.getenv('TELEGRAM_CHANNEL_ID')
RSS_FEEDS_FILE = "rss_feeds.txt"  # å­˜å‚¨ RSS è®¢é˜…é“¾æ¥çš„æ–‡ä»¶
MAX_MESSAGE_LENGTH = 4096  # Telegram æ¶ˆæ¯é•¿åº¦é™åˆ¶
SUMMARY_MAX_LENGTH = 100  # æ‘˜è¦æœ€å¤§é•¿åº¦
MAX_ARTICLES_PER_FEED = 5  # æ¯ä¸ªç½‘ç«™æœ€å¤šæŠ“å– 5 æ¡æ–‡ç« 
RETRY_COUNT = 3  # RSS æºæŠ“å–é‡è¯•æ¬¡æ•°

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def load_rss_feeds():
    """ä»æ–‡ä»¶ä¸­åŠ è½½ RSS è®¢é˜…é“¾æ¥"""
    if not os.path.exists(RSS_FEEDS_FILE):
        logging.error(f"RSS feeds file '{RSS_FEEDS_FILE}' not found.")
        return []
    
    with open(RSS_FEEDS_FILE, "r", encoding="utf-8") as file:
        feeds = [line.strip() for line in file if line.strip()]
    return feeds

def clean_html(html):
    """æ¸…ç† HTML æ ‡ç­¾ï¼Œæå–çº¯æ–‡æœ¬"""
    soup = BeautifulSoup(html, 'html.parser')
    return soup.get_text().strip()

def parse_entry_time(entry):
    """è§£ææ¡ç›®çš„å‘å¸ƒæ—¶é—´"""
    if hasattr(entry, 'published_parsed'):
        return datetime(*entry.published_parsed[:6])
    elif hasattr(entry, 'updated_parsed'):
        return datetime(*entry.updated_parsed[:6])
    elif hasattr(entry, 'published'):
        try:
            return datetime.strptime(entry.published, '%a, %d %b %Y %H:%M:%S %z')
        except ValueError:
            pass
    elif hasattr(entry, 'updated'):
        try:
            return datetime.strptime(entry.updated, '%a, %d %b %Y %H:%M:%S %z')
        except ValueError:
            pass
    return None

async def fetch_feed(session, rss_url):
    """å¼‚æ­¥æŠ“å– RSS æº"""
    for attempt in range(RETRY_COUNT):
        try:
            async with session.get(rss_url) as response:
                if response.status != 200:
                    logging.error(f"Attempt {attempt + 1} failed for {rss_url}: HTTP {response.status}")
                    continue
                content = await response.text()
                feed = feedparser.parse(content)
                return feed
        except Exception as e:
            logging.error(f"Attempt {attempt + 1} failed for {rss_url}: {e}")
            await asyncio.sleep(2)  # ç­‰å¾… 2 ç§’åé‡è¯•
    return None

async def fetch_new_articles(session, rss_url):
    """ä»æŒ‡å®š RSS æºè·å–å½“å¤©çš„æ–°æ–‡ç« """
    feed = await fetch_feed(session, rss_url)
    if not feed:
        return []
    
    new_articles = []
    today = datetime.now()
    start_of_day = datetime(today.year, today.month, today.day)
    
    for entry in feed.entries[:MAX_ARTICLES_PER_FEED]:
        published_time = parse_entry_time(entry)
        if published_time is None:
            logging.warning(f"Skipping entry due to missing time info: {entry.link}")
            continue
        
        if published_time >= start_of_day:
            title = clean_html(entry.title) if 'title' in entry else 'æ— æ ‡é¢˜'
            summary = clean_html(entry.summary) if 'summary' in entry else 'æš‚æ— æ‘˜è¦'
            summary = summary[:SUMMARY_MAX_LENGTH]  # æˆªå–å‰ 100 å­—ç¬¦
            if len(summary) == SUMMARY_MAX_LENGTH:
                summary += '...'  # æ·»åŠ çœç•¥å·
            
            new_articles.append({
                'title': title,
                'link': entry.link,
                'summary': summary,
                'source': feed.feed.title if 'title' in feed.feed else 'æœªçŸ¥æ¥æº'
            })
    
    return new_articles

async def send_to_telegram(message):
    """å‘é€æ¶ˆæ¯åˆ° Telegram é¢‘é“"""
    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    payload = {
        'chat_id': TELEGRAM_CHANNEL_ID,
        'text': message,
        'parse_mode': 'Markdown'
    }
    
    async with aiohttp.ClientSession() as session:
        async with session.post(url, data=payload) as response:
            if response.status != 200:
                logging.error(f"Failed to send message: {await response.text()}")

def get_title_icon(source):
    """æ ¹æ®æ¥æºè¿”å›æ ‡é¢˜å‰çš„è¡¨æƒ…ç¬¦å·"""
    icon_map = {
        'çŸ¥ä¹': 'ğŸ“Œ',
        '36æ°ª': 'ğŸ”¥',
        'æŠ½å±‰': 'ğŸŒŸ',
        'å°‘æ•°æ´¾': 'ğŸ“±',
        'è™å—…': 'ğŸ¯',
        'é’›åª’ä½“': 'ğŸš€',
        'å¾®ä¿¡': 'ğŸ’¬',
        'Appinn': 'ğŸ“²',
        'è´¢æ–°': 'ğŸ’°',
        'V2EX': 'ğŸ’»',
        'æ¾é¼ ä¼š': 'ğŸ¿ï¸',
        'è¯‘è¨€': 'ğŸŒ'
    }
    for key, icon in icon_map.items():
        if key in source:
            return icon
    return 'ğŸ“°'  # é»˜è®¤æ ‡è®°ä¸ºæ–°é—»

async def main():
    """ä¸»å‡½æ•°ï¼šè·å–å¤šä¸ªç½‘ç«™çš„æ–°æ–‡ç« å¹¶å‘é€åˆ° Telegram"""
    rss_feeds = load_rss_feeds()
    if not rss_feeds:
        logging.error("No RSS feeds found.")
        return
    
    all_articles = []
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_new_articles(session, rss_url) for rss_url in rss_feeds]
        results = await asyncio.gather(*tasks)
        for articles in results:
            all_articles.extend(articles)
    
    if all_articles:
        for article in all_articles:
            icon = get_title_icon(article['source'])
            message = (
                f"{icon} [{article['title']}]({article['link']})\n"
                f"ğŸ“° **æ¥æº**: {article['source']}\n\n"
                f"{article['summary']}"
            )
            await send_to_telegram(message)
    else:
        logging.info("ä»Šæ—¥æ²¡æœ‰æ–°æ–‡ç« ã€‚")

if __name__ == "__main__":
    asyncio.run(main())
